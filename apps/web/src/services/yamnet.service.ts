import * as tf from '@tensorflow/tfjs'
import type { AudioData, InferenceResult } from '../store/types'

/**
 * YAMNetéŸ³éŸ¿åˆ†é¡çµæœã®å‹å®šç¾©
 */
export interface YAMNetClassification {
   /** AudioSetã‚¯ãƒ©ã‚¹å */
   className: string
   /** ä¿¡é ¼åº¦ (0-1) */
   confidence: number
   /** AudioSetã‚¯ãƒ©ã‚¹ID */
   classId: number
}

/**
 * éŸ³éŸ¿ç’°å¢ƒã®åˆ†é¡çµæœ
 */
export interface SoundEnvironmentResult {
   /** ä¸»è¦ãªéŸ³ã®ç¨®é¡ */
   primarySound: InferenceResult
   /** ç’°å¢ƒã‚¿ã‚¤ãƒ— */
   environment: 'indoor' | 'outdoor' | 'urban' | 'natural' | 'unknown'
   /** å…¨åˆ†é¡çµæœï¼ˆä¸Šä½5ã¤ï¼‰ */
   allClassifications: YAMNetClassification[]
}

/**
 * YAMNetéŸ³éŸ¿åˆ†é¡ã‚µãƒ¼ãƒ“ã‚¹
 *
 * @description
 * TensorFlow.jsã¨YAMNetãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦éŸ³éŸ¿åˆ†é¡ã‚’å®Ÿè¡Œ
 * AudioSetã®521ã‚¯ãƒ©ã‚¹ã‹ã‚‰ç’°å¢ƒéŸ³ã‚’åˆ†é¡ã—ã€Sonoryç”¨ã®çµæœã«å¤‰æ›
 */
export class YAMNetService {
   private model: tf.GraphModel | null = null
   private classNames: string[] = []
   private isLoading = false

   /**
    * YAMNetãƒ¢ãƒ‡ãƒ«ã®URL
    */
   private readonly modelUrl = 'https://tfhub.dev/google/yamnet/1'

   /**
    * å¯¾è±¡ã¨ãªã‚‹ç’°å¢ƒéŸ³ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
    */
   private readonly soundMapping: Record<string, string> = {
      Vehicle: 'è»Šã®éŸ³',
      Car: 'è»Šã®éŸ³',
      'Motor vehicle': 'è»Šã®éŸ³',
      Truck: 'ãƒˆãƒ©ãƒƒã‚¯ã®éŸ³',
      Bus: 'ãƒã‚¹ã®éŸ³',
      Motorcycle: 'ãƒã‚¤ã‚¯ã®éŸ³',
      Bicycle: 'è‡ªè»¢è»Šã®éŸ³',
      'Traffic noise': 'äº¤é€šéŸ³',
      Train: 'é›»è»Šã®éŸ³',
      Subway: 'åœ°ä¸‹é‰„ã®éŸ³',
      Aircraft: 'é£›è¡Œæ©Ÿã®éŸ³',
      Helicopter: 'ãƒ˜ãƒªã‚³ãƒ—ã‚¿ãƒ¼ã®éŸ³',

      Rain: 'é›¨éŸ³',
      Thunderstorm: 'é›·é›¨',
      Wind: 'é¢¨ã®éŸ³',
      'Rain on surface': 'é›¨éŸ³',
      Drip: 'æ°´æ»´ã®éŸ³',

      Bird: 'é³¥ã®é³´ãå£°',
      'Bird vocalization': 'é³¥ã®é³´ãå£°',
      Crow: 'ã‚«ãƒ©ã‚¹ã®é³´ãå£°',
      Pigeon: 'é³©ã®é³´ãå£°',
      Seagull: 'ã‚«ãƒ¢ãƒ¡ã®é³´ãå£°',

      Dog: 'çŠ¬ã®é³´ãå£°',
      Cat: 'çŒ«ã®é³´ãå£°',
      Animal: 'å‹•ç‰©ã®å£°',

      'Construction noise': 'å·¥äº‹ã®éŸ³',
      Jackhammer: 'ãƒ‰ãƒªãƒ«ã®éŸ³',
      Hammer: 'ãƒãƒ³ãƒãƒ¼ã®éŸ³',
      'Power tool': 'é›»å‹•å·¥å…·ã®éŸ³',

      Music: 'éŸ³æ¥½',
      Speech: 'äººã®å£°',
      Crowd: 'äººæ··ã¿ã®éŸ³',
      Footsteps: 'è¶³éŸ³',
      Door: 'ãƒ‰ã‚¢ã®éŸ³',
      Bell: 'ãƒ™ãƒ«ã®éŸ³',
      Siren: 'ã‚µã‚¤ãƒ¬ãƒ³',

      Water: 'æ°´ã®éŸ³',
      Stream: 'å·ã®éŸ³',
      Ocean: 'æµ·ã®éŸ³',
      Wave: 'æ³¢ã®éŸ³',
   }

   /**
    * ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
    */
   async initialize(): Promise<void> {
      if (this.model || this.isLoading) return

      try {
         this.isLoading = true
         console.log('ğŸ¤– YAMNetãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...')

         // TensorFlow.jsã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’åˆæœŸåŒ–
         await tf.ready()

         // YAMNetãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
         this.model = await tf.loadGraphModel(this.modelUrl)

         // ã‚¯ãƒ©ã‚¹åã‚’å–å¾—ï¼ˆAudioSetã®ã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ—ï¼‰
         await this.loadClassNames()

         console.log('âœ… YAMNetãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–å®Œäº†')
         console.log(`ğŸ“Š å¯¾å¿œã‚¯ãƒ©ã‚¹æ•°: ${this.classNames.length}`)
      } catch (error) {
         console.error('âŒ YAMNetãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—:', error)
         throw new Error('YAMNetãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ')
      } finally {
         this.isLoading = false
      }
   }

   /**
    * AudioSetã®ã‚¯ãƒ©ã‚¹åã‚’èª­ã¿è¾¼ã¿
    */
   private async loadClassNames(): Promise<void> {
      try {
         // AudioSetã®ã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ—ã‚’å–å¾—
         const response = await fetch(
            'https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv'
         )
         const csvText = await response.text()

         // CSVã‚’ãƒ‘ãƒ¼ã‚¹
         const lines = csvText.trim().split('\n')
         this.classNames = lines.slice(1).map(line => {
            const parts = line.split(',')
            return parts[2]?.replace(/"/g, '') || '' // display_nameåˆ—
         })
      } catch (error) {
         console.warn('âš ï¸ ã‚¯ãƒ©ã‚¹åã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ãƒ©ã‚¹åã‚’ä½¿ç”¨:', error)
         // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»£è¡¨çš„ãªã‚¯ãƒ©ã‚¹åã‚’æ‰‹å‹•å®šç¾©
         this.classNames = this.getDefaultClassNames()
      }
   }

   /**
    * ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ãƒ©ã‚¹åï¼ˆã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ—å–å¾—å¤±æ•—æ™‚ï¼‰
    */
   private getDefaultClassNames(): string[] {
      return [
         'Speech',
         'Male speech',
         'Female speech',
         'Child speech',
         'Conversation',
         'Narration',
         'Babbling',
         'Speech synthesizer',
         'Shout',
         'Bellow',
         'Music',
         'Musical instrument',
         'Piano',
         'Guitar',
         'Drum',
         'Vehicle',
         'Car',
         'Motor vehicle',
         'Truck',
         'Bus',
         'Motorcycle',
         'Traffic noise',
         'Train',
         'Aircraft',
         'Helicopter',
         'Animal',
         'Dog',
         'Cat',
         'Bird',
         'Bird vocalization',
         'Water',
         'Rain',
         'Thunder',
         'Wind',
         'Stream',
         'Construction noise',
         'Power tool',
         'Hammer',
         'Jackhammer',
         'Bell',
         'Siren',
         'Alarm',
         'Footsteps',
         'Door',
      ]
   }

   /**
    * éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰éŸ³éŸ¿åˆ†é¡ã‚’å®Ÿè¡Œ
    */
   async classifyAudio(audioData: AudioData): Promise<SoundEnvironmentResult> {
      if (!this.model) {
         await this.initialize()
      }

      if (!this.model) {
         throw new Error('YAMNetãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“')
      }

      try {
         console.log('ğŸµ éŸ³éŸ¿åˆ†æã‚’é–‹å§‹...')

         // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
         const audioTensor = await this.preprocessAudio(audioData.blob)

         // YAMNetã§æ¨è«–å®Ÿè¡Œ
         const predictions = this.model.predict(audioTensor) as tf.Tensor
         const scores = await predictions.data()

         // çµæœã‚’è§£æ
         const classifications = this.parseClassifications(Array.from(scores))
         const result = this.createSoundEnvironmentResult(classifications)

         // ãƒ¡ãƒ¢ãƒªè§£æ”¾
         audioTensor.dispose()
         predictions.dispose()

         console.log('âœ… éŸ³éŸ¿åˆ†æå®Œäº†:', result.primarySound)
         return result
      } catch (error) {
         console.error('âŒ éŸ³éŸ¿åˆ†æã«å¤±æ•—:', error)
         throw new Error('éŸ³éŸ¿åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ')
      }
   }

   /**
    * éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ï¼ˆYAMNetç”¨ï¼‰
    */
   private async preprocessAudio(audioBlob: Blob): Promise<tf.Tensor> {
      return new Promise((resolve, reject) => {
         const audio = new Audio()
         const AudioContextClass =
            window.AudioContext ||
            (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext
         const audioContext = new AudioContextClass()

         const reader = new FileReader()
         reader.onload = async e => {
            try {
               const arrayBuffer = e.target?.result as ArrayBuffer
               const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)

               // ãƒ¢ãƒãƒ©ãƒ«åŒ–
               const channelData = audioBuffer.getChannelData(0)

               // 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆYAMNetè¦ä»¶ï¼‰
               const targetSampleRate = 16000
               const resampledData = this.resampleAudio(
                  channelData,
                  audioBuffer.sampleRate,
                  targetSampleRate
               )

               // ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
               const audioTensor = tf.tensor1d(resampledData)
               resolve(audioTensor)
            } catch (error) {
               reject(error)
            }
         }

         reader.onerror = () => reject(new Error('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—'))
         reader.readAsArrayBuffer(audioBlob)
      })
   }

   /**
    * éŸ³å£°ã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    */
   private resampleAudio(
      audioData: Float32Array,
      originalSampleRate: number,
      targetSampleRate: number
   ): Float32Array {
      if (originalSampleRate === targetSampleRate) {
         return audioData
      }

      const ratio = originalSampleRate / targetSampleRate
      const newLength = Math.round(audioData.length / ratio)
      const result = new Float32Array(newLength)

      for (let i = 0; i < newLength; i++) {
         const index = i * ratio
         const lowerIndex = Math.floor(index)
         const upperIndex = Math.min(lowerIndex + 1, audioData.length - 1)
         const fraction = index - lowerIndex

         result[i] = audioData[lowerIndex] * (1 - fraction) + audioData[upperIndex] * fraction
      }

      return result
   }

   /**
    * åˆ†é¡çµæœã‚’ãƒ‘ãƒ¼ã‚¹
    */
   private parseClassifications(scores: number[]): YAMNetClassification[] {
      const classifications: YAMNetClassification[] = []

      for (let i = 0; i < scores.length && i < this.classNames.length; i++) {
         if (scores[i] > 0.01) {
            // ä¿¡é ¼åº¦1%ä»¥ä¸Šã®ã¿
            classifications.push({
               className: this.classNames[i] || `Class_${i}`,
               confidence: scores[i],
               classId: i,
            })
         }
      }

      // ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
      return classifications.sort((a, b) => b.confidence - a.confidence)
   }

   /**
    * Sonoryç”¨ã®çµæœã«å¤‰æ›
    */
   private createSoundEnvironmentResult(
      classifications: YAMNetClassification[]
   ): SoundEnvironmentResult {
      const topClassifications = classifications.slice(0, 5)

      // æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„åˆ†é¡ã‚’æ—¥æœ¬èªã«å¤‰æ›
      const primaryClassification = topClassifications[0]
      const japaneseLabel = this.mapToJapanese(primaryClassification?.className || 'Unknown')

      // ç’°å¢ƒã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
      const environment = this.detectEnvironment(topClassifications)

      return {
         primarySound: {
            label: japaneseLabel,
            confidence: primaryClassification?.confidence || 0,
         },
         environment,
         allClassifications: topClassifications,
      }
   }

   /**
    * è‹±èªã‚¯ãƒ©ã‚¹åã‚’æ—¥æœ¬èªã«ãƒãƒƒãƒ”ãƒ³ã‚°
    */
   public mapToJapanese(className: string): string {
      // å®Œå…¨ä¸€è‡´ã‚’æ¢ã™
      if (this.soundMapping[className]) {
         return this.soundMapping[className]
      }

      // éƒ¨åˆ†ä¸€è‡´ã‚’æ¢ã™
      for (const [key, value] of Object.entries(this.soundMapping)) {
         if (
            className.toLowerCase().includes(key.toLowerCase()) ||
            key.toLowerCase().includes(className.toLowerCase())
         ) {
            return value
         }
      }

      // ãƒãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®åå‰ã‚’è¿”ã™
      return className
   }

   /**
    * éŸ³éŸ¿ç’°å¢ƒã‚’æ¨å®š
    */
   private detectEnvironment(
      classifications: YAMNetClassification[]
   ): 'indoor' | 'outdoor' | 'urban' | 'natural' | 'unknown' {
      const classNames = classifications.map(c => c.className.toLowerCase())

      // è‡ªç„¶ç’°å¢ƒã®éŸ³
      if (
         classNames.some(
            name =>
               name.includes('bird') ||
               name.includes('water') ||
               name.includes('rain') ||
               name.includes('wind') ||
               name.includes('thunder') ||
               name.includes('stream')
         )
      ) {
         return 'natural'
      }

      // éƒ½å¸‚ç’°å¢ƒã®éŸ³
      if (
         classNames.some(
            name =>
               name.includes('vehicle') ||
               name.includes('traffic') ||
               name.includes('car') ||
               name.includes('construction') ||
               name.includes('siren') ||
               name.includes('horn')
         )
      ) {
         return 'urban'
      }

      // å±‹å†…ã®éŸ³
      if (
         classNames.some(
            name =>
               name.includes('speech') ||
               name.includes('music') ||
               name.includes('door') ||
               name.includes('footsteps')
         )
      ) {
         return 'indoor'
      }

      // ãã®ä»–ã¯å±‹å¤–ã¨ã—ã¦åˆ†é¡
      return 'outdoor'
   }

   /**
    * ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‚’å–å¾—
    */
   get isReady(): boolean {
      return this.model !== null
   }

   /**
    * ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
    */
   dispose(): void {
      if (this.model) {
         this.model.dispose()
         this.model = null
      }
   }
}
